{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "MZ2xnvvgDfPU",
        "GBhxIUgNuH-P",
        "GqV1B3kCuLUb",
        "x_CMEvhouOLv",
        "4gcc_2RV0Ivu",
        "l6gldprJ0MXk",
        "jWyvDOv70Rwz",
        "QWpzYGV81KGP",
        "LauQaTbwnOsR",
        "BpPBVfYFn1Fh",
        "N4830g45e2F8",
        "Xb_ilxcPeeYt",
        "IdUNN084Ws1I",
        "XwCz3rCy4zQK",
        "4vV8kPRXEYcZ",
        "dyD6xQSto_NJ",
        "oNJ54-eEWvx2",
        "yx73jVXAWzM5",
        "-pcmMw0rZ7xf"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNpWwq8snnrt+WHfj4QFNwd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EngSoftwareEngineer/GNN/blob/main/Parking_Space_Occupancy_LLM_GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "b2U2XJhn-_aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RPTM_reid"
      ],
      "metadata": {
        "id": "MZ2xnvvgDfPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1XD3O3OXZddS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "repo_path = '/content/drive/MyDrive/Colab Notebooks/RPTM_reid-main'  # این مسیر را با مسیر دقیق خودتان جایگزین کنید\n",
        "os.chdir(repo_path)"
      ],
      "metadata": {
        "id": "VQee9xpjKwCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Bq0hbHSWa1dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XA7OOGjtLUt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/apex.git\n",
        "!cd apex\n"
      ],
      "metadata": {
        "id": "w0GIjEEcZVy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "repo_path = '/content/drive/MyDrive/Colab Notebooks/RPTM_reid-main'  # مسیر درست به پوشه اصلی ریپازیتوری\n",
        "os.chdir(repo_path)\n"
      ],
      "metadata": {
        "id": "FDjew2w2Merc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --config_file configs/veri_r101.yml\n"
      ],
      "metadata": {
        "id": "ERtvCUOMLtmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir logs\n",
        "!python main.py --config_file configs/veri_r101.yml TEST.WEIGHT '<path to trained model>' TEST.EVAL True"
      ],
      "metadata": {
        "id": "8ux3wBmUMHhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show apex"
      ],
      "metadata": {
        "id": "wfg7htLVYzwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#kaggle API"
      ],
      "metadata": {
        "id": "GBhxIUgNuH-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "qZG3ViadjJgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = 'engkaffash'\n",
        "os.environ['KAGGLE_KEY'] = 'b814a26f43bb2071991c9b7a0cb013b8'\n"
      ],
      "metadata": {
        "id": "r1wScN04mFtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Duck dataset"
      ],
      "metadata": {
        "id": "GqV1B3kCuLUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kaggle\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# دانلود فایل زیپ از Kaggle\n",
        "dataset_path = 'whurobin/dukemtmcreid'  # مسیر دیتاست روی Kaggle\n",
        "output_path = '/content/drive/MyDrive/Colab Notebooks/RPTM_reid-main/data/duck'  # مسیری که می‌خواهید دیتاست را استخراج کنید\n",
        "\n",
        "# بررسی وجود پوشه مقصد\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "# دانلود دیتاست\n",
        "kaggle.api.dataset_download_files(dataset_path, path=output_path, unzip=True)\n",
        "\n",
        "# استخراج فایل زیپ (اگر unzip=False تنظیم شده باشد)\n",
        "zip_file_path = os.path.join(output_path, 'dukemtmcreid.zip')\n",
        "if os.path.exists(zip_file_path):\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(output_path)\n",
        "    os.remove(zip_file_path)\n"
      ],
      "metadata": {
        "id": "U4jrlIC2lc3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Veri Dataset"
      ],
      "metadata": {
        "id": "x_CMEvhouOLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import kaggle\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "# مشخص کردن مسیر برای ذخیره‌سازی داده‌ها\n",
        "dataset_path = '/content/drive/MyDrive/Colab Notebooks/RPTM_reid-main/data/veri'\n",
        "if not os.path.exists(dataset_path):\n",
        "    os.makedirs(dataset_path)\n",
        "\n",
        "# دانلود فایل از Kaggle\n",
        "dataset_url = 'abhyudaya12/veri-vehicle-re-identification-dataset'\n",
        "kaggle.api.dataset_download_files(dataset_url, path=dataset_path, unzip=False)\n",
        "\n",
        "# نام فایل ZIP دانلود شده\n",
        "zip_filename = os.path.join(dataset_path, 'veri-vehicle-re-identification-dataset.zip')\n",
        "\n",
        "# استخراج فایل ZIP\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(dataset_path)\n",
        "\n",
        "print('دانلود و استخراج فایل به پایان رسید.')\n"
      ],
      "metadata": {
        "id": "qIM8cSacqlJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RCNN"
      ],
      "metadata": {
        "id": "xXCNaEicGWeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import time\n",
        "import requests\n",
        "import zipfile\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "1qh2PMr7-eJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clone the git repository and set it as the working directory\n",
        "! git clone https://github.com/martin-marek/parking-space-occupancy\n",
        "os.chdir('parking-space-occupancy')"
      ],
      "metadata": {
        "id": "Wc9cmWqe-gnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the dataset\n",
        "if not os.path.exists('dataset/data'):\n",
        "    r = requests.get(\"https://pub-e8bbdcbe8f6243b2a9933704a9b1d8bc.r2.dev/parking%2Frois_gopro.zip\")\n",
        "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "    z.extractall('dataset/data')"
      ],
      "metadata": {
        "id": "qQp4z0Us-i56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset import acpds\n",
        "from utils import transforms\n",
        "from utils import visualize as vis"
      ],
      "metadata": {
        "id": "6iq-aQIf-lS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, valid_ds, test_ds = acpds.create_datasets('dataset/data')"
      ],
      "metadata": {
        "id": "m4iFotmM-nfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_batch, rois_batch, labels_batch = next(iter(valid_ds))\n",
        "image_raw, rois, labels = image_batch[0], rois_batch[0], labels_batch[0]\n",
        "image = transforms.preprocess(image_raw, res=1440)\n",
        "vis.plot_ds_image(image, rois, labels, show=True)"
      ],
      "metadata": {
        "id": "fB2M_yyz-pWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#اتصال همه به همه"
      ],
      "metadata": {
        "id": "XHEjOaMCnK1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "node_ids = list(range(len(rois)))\n",
        "graph = nx.Graph()\n",
        "\n",
        "# افزودن نودها به گراف با برچسب‌های پر یا خالی\n",
        "for i, roi in enumerate(rois):\n",
        "    label = labels[i].item()\n",
        "    graph.add_node(node_ids[i], occupied=label)\n",
        "\n",
        "# اتصال نودها بر اساس مجاورت یا معیارهای دیگر (در اینجا اتصال همه به همه)\n",
        "for i in range(len(rois)):\n",
        "    for j in range(i+1, len(rois)):\n",
        "        graph.add_edge(node_ids[i], node_ids[j])\n",
        "\n",
        "# نمایش گراف\n",
        "nx.draw(graph, with_labels=True, node_color=[\"red\" if graph.nodes[i][\"occupied\"] else \"green\" for i in graph.nodes])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7WL7QHrUjczi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4A7kU1bdmE1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import from_networkx\n",
        "\n",
        "# تبدیل گراف NetworkX به فرمت داده‌ای PyTorch Geometric\n",
        "data = from_networkx(graph)\n",
        "\n",
        "# افزودن ویژگی‌های نودها به عنوان یک tensor\n",
        "data.x = torch.tensor([graph.nodes[i][\"occupied\"] for i in graph.nodes], dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "# برچسب‌های نودها (occupied یا vacant) را به data.y اختصاص دهید\n",
        "# فرض می‌کنیم 1 برای occupied (پر) و 0 برای vacant (خالی)\n",
        "data.y = torch.tensor([graph.nodes[i][\"occupied\"] for i in graph.nodes], dtype=torch.long)\n",
        "\n",
        "# بررسی داده‌ها\n",
        "print(data)\n"
      ],
      "metadata": {
        "id": "zHYCXltJje6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GCNConv"
      ],
      "metadata": {
        "id": "4gcc_2RV0Ivu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.optim as optim\n",
        "\n",
        "# افزودن وزنه‌های کلاس‌ها برای مقابله با عدم تعادل داده‌ها\n",
        "weights = torch.tensor([0.7, 1.3])  # فرضیه: کلاس 0 (خالی) کمتر است\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "# افزایش تعداد لایه‌های GNN یا تغییر نوع مدل\n",
        "class ImprovedGNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedGNN, self).__init__()\n",
        "        self.conv1 = GCNConv(1, 32)\n",
        "        self.conv2 = GCNConv(32, 64)\n",
        "        self.conv3 = GCNConv(64, 32)\n",
        "        self.conv4 = GCNConv(32, 2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv4(x, edge_index)\n",
        "        return torch.log_softmax(x, dim=1)\n",
        "\n",
        "# ادامه مراحل آموزش و ارزیابی با مدل بهبود یافته\n",
        "model = ImprovedGNN()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# آموزش مدل با معماری جدید و وزن‌های کلاس\n",
        "model.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "id": "gdHqSv8Dlg0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "_, pred = model(data).max(dim=1)\n",
        "correct = (pred == data.y).sum().item()\n",
        "accuracy = correct / len(data.y)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "05WT2Rk-jtos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(data)\n",
        "    _, preds = outputs.max(dim=1)\n",
        "\n",
        "\n",
        "y_true = data.y.numpy()\n",
        "y_pred = preds.numpy()\n",
        "\n",
        "# محاسبه F1-Score\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')  # 'weighted' برای محاسبه میانگین وزنی\n",
        "print(f'F1 Score: {f1:.4f}')\n"
      ],
      "metadata": {
        "id": "lgeIDbTb4Zfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GATConv"
      ],
      "metadata": {
        "id": "l6gldprJ0MXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import GATConv\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# تعریف مدل GNN بهبود یافته\n",
        "class ImprovedGNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedGNN, self).__init__()\n",
        "        self.conv1 = GATConv(1, 16)\n",
        "        self.conv2 = GATConv(16, 32)\n",
        "        self.conv3 = GATConv(32, 2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        return torch.log_softmax(x, dim=1)\n",
        "\n",
        "# تنظیم وزن کلاس‌ها برای تعادل\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.0]))\n",
        "\n",
        "# تعریف مدل، optimizer\n",
        "model = ImprovedGNN()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# آموزش مدل\n",
        "model.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # نرمال‌سازی گرادیان‌ها\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "id": "S3Ns8nUFt31T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "_, pred = model(data).max(dim=1)\n",
        "correct = (pred == data.y).sum().item()\n",
        "accuracy = correct / len(data.y)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "DFueqQ_Yt9YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positions = {i: (np.random.rand(), np.random.rand()) for i in graph.nodes}\n",
        "\n",
        "# رسم گراف\n",
        "plt.figure(figsize=(10, 10))\n",
        "pos = positions\n",
        "nx.draw(graph, pos, with_labels=True, node_color=[\"red\" if graph.nodes[i][\"occupied\"] else \"green\" for i in graph.nodes])\n",
        "plt.title('Graph Visualization')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "G3kRQhES6dd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(data)\n",
        "    _, preds = outputs.max(dim=1)\n",
        "\n",
        "\n",
        "y_true = data.y.numpy()\n",
        "y_pred = preds.numpy()\n",
        "\n",
        "# محاسبه F1-Score\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')  # 'weighted' برای محاسبه میانگین وزنی\n",
        "print(f'F1 Score: {f1:.4f}')\n"
      ],
      "metadata": {
        "id": "w_AiJyE44ue7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "id": "9ruLAu5VuBaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "id": "N4KMQ24Zt-mU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# بارگذاری مدل و توکنایزر\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "llm_model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# ساخت متن برای پردازش\n",
        "text = f\"Model GNN Predictions: {pred.tolist()}\\nTrue Labels: {data.y.tolist()}\\nAccuracy: {accuracy:.4f}\\n\"\n",
        "\n",
        "# توکنایز و آماده‌سازی داده‌ها برای مدل LLM\n",
        "inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
        "\n",
        "# پردازش داده‌ها با مدل LLM\n",
        "with torch.no_grad():\n",
        "    outputs = llm_model(**inputs)\n",
        "\n",
        "# خروجی مدل LLM\n",
        "logits = outputs.logits\n",
        "\n",
        "# تبدیل logits به احتمالات (اختیاری)\n",
        "probabilities = torch.softmax(logits, dim=-1)\n"
      ],
      "metadata": {
        "id": "YxM9Q8dlvHjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# بارگذاری مدل تولید متن (مثل GPT-2)\n",
        "text_generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "# تولید توضیحات\n",
        "generated_text = text_generator(f\"Explain the results of GNN model. {text}\", max_length=400)\n",
        "print(generated_text[0]['generated_text'])\n"
      ],
      "metadata": {
        "id": "yyB37KS3vM6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# بارگذاری مدل و توکنایزر\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "llm_model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# محاسبه تعداد جاهای خالی و تعداد ماشین‌های پارک شده\n",
        "num_occupied = (data.y == 1).sum().item()\n",
        "num_empty = (data.y == 0).sum().item()\n",
        "\n",
        "# ساخت متن برای پردازش\n",
        "text = (f\"Model GNN Predictions: {pred.tolist()}\\n\"\n",
        "        f\"True Labels: {data.y.tolist()}\\n\"\n",
        "        f\"Accuracy: {accuracy:.4f}\\n\"\n",
        "        f\"Number of parked cars: {num_occupied}\\n\"\n",
        "        f\"Number of empty spaces: {num_empty}\\n\")\n",
        "\n",
        "# توکنایز و آماده‌سازی داده‌ها برای مدل LLM\n",
        "inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
        "\n",
        "# پردازش داده‌ها با مدل LLM\n",
        "with torch.no_grad():\n",
        "    outputs = llm_model(**inputs)\n",
        "\n",
        "# خروجی مدل LLM\n",
        "logits = outputs.logits\n",
        "\n",
        "# تبدیل logits به احتمالات (اختیاری)\n",
        "probabilities = torch.softmax(logits, dim=-1)\n",
        "\n",
        "# چاپ نتایج\n",
        "print(\"Logits:\", logits)\n",
        "print(\"Probabilities:\", probabilities)\n"
      ],
      "metadata": {
        "id": "UAkZxZP8wiIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# بارگذاری مدل تولید متن (مثل GPT-2)\n",
        "text_generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "# تولید توضیحات\n",
        "generated_text = text_generator(text, max_new_tokens=150)  # تنظیم تعداد توکن‌های جدید\n",
        "print(generated_text[0]['generated_text'])\n"
      ],
      "metadata": {
        "id": "6Sr2qa-PwksC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GrapSAGE"
      ],
      "metadata": {
        "id": "jWyvDOv70Rwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# تعریف مدل GNN بهبود یافته با SAGEConv\n",
        "class ImprovedGNN_SAGE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedGNN_SAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(1, 16)  # تغییر از GATConv به SAGEConv\n",
        "        self.conv2 = SAGEConv(16, 32)  # تغییر از GATConv به SAGEConv\n",
        "        self.conv3 = SAGEConv(32, 2)   # تغییر از GATConv به SAGEConv\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        return torch.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "pJXqvNCG0T8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تنظیم وزن کلاس‌ها برای تعادل\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.0]))\n",
        "\n",
        "# تعریف مدل، optimizer\n",
        "model = ImprovedGNN_SAGE()  # استفاده از مدل SAGEConv\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# آموزش مدل\n",
        "model.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # نرمال‌سازی گرادیان‌ها\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "id": "ZZJMIqjb0Wf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "_, pred = model(data).max(dim=1)\n",
        "correct = (pred == data.y).sum().item()\n",
        "accuracy = correct / len(data.y)\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "MFYCXNf_0lj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(data)\n",
        "    _, preds = outputs.max(dim=1)\n",
        "\n",
        "\n",
        "y_true = data.y.numpy()\n",
        "y_pred = preds.numpy()\n",
        "\n",
        "# محاسبه F1-Score\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')  # 'weighted' برای محاسبه میانگین وزنی\n",
        "print(f'F1 Score: {f1:.4f}')\n"
      ],
      "metadata": {
        "id": "4Qpdgghk4yyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "id": "IpgMFJiR0oFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "id": "4ZGa7F8M0rYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# بارگذاری مدل و توکنایزر\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "llm_model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# ساخت متن برای پردازش\n",
        "text = f\"Model GNN Predictions: {pred.tolist()}\\nTrue Labels: {data.y.tolist()}\\nAccuracy: {accuracy:.4f}\\n\"\n",
        "\n",
        "# توکنایز و آماده‌سازی داده‌ها برای مدل LLM\n",
        "inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
        "\n",
        "# پردازش داده‌ها با مدل LLM\n",
        "with torch.no_grad():\n",
        "    outputs = llm_model(**inputs)\n",
        "\n",
        "# خروجی مدل LLM\n",
        "logits = outputs.logits\n",
        "\n",
        "# تبدیل logits به احتمالات (اختیاری)\n",
        "probabilities = torch.softmax(logits, dim=-1)"
      ],
      "metadata": {
        "id": "teKmuOW80sgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# بارگذاری مدل تولید متن (مثل GPT-2)\n",
        "text_generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "# تولید توضیحات\n",
        "generated_text = text_generator(f\"Explain the results of GNN model. {text}\", max_length=400)\n",
        "print(generated_text[0]['generated_text'])\n"
      ],
      "metadata": {
        "id": "yGndYOBE0y4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# بارگذاری مدل و توکنایزر\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "llm_model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# محاسبه تعداد جاهای خالی و تعداد ماشین‌های پارک شده\n",
        "num_occupied = (data.y == 1).sum().item()\n",
        "num_empty = (data.y == 0).sum().item()\n",
        "\n",
        "# ساخت متن برای پردازش\n",
        "text = (f\"Model GNN Predictions: {pred.tolist()}\\n\"\n",
        "        f\"True Labels: {data.y.tolist()}\\n\"\n",
        "        f\"Accuracy: {accuracy:.4f}\\n\"\n",
        "        f\"Number of parked cars: {num_occupied}\\n\"\n",
        "        f\"Number of empty spaces: {num_empty}\\n\")\n",
        "\n",
        "# توکنایز و آماده‌سازی داده‌ها برای مدل LLM\n",
        "inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
        "\n",
        "# پردازش داده‌ها با مدل LLM\n",
        "with torch.no_grad():\n",
        "    outputs = llm_model(**inputs)\n",
        "\n",
        "# خروجی مدل LLM\n",
        "logits = outputs.logits\n",
        "\n",
        "# تبدیل logits به احتمالات (اختیاری)\n",
        "probabilities = torch.softmax(logits, dim=-1)\n",
        "\n",
        "# چاپ نتایج\n",
        "print(\"Logits:\", logits)\n",
        "print(\"Probabilities:\", probabilities)"
      ],
      "metadata": {
        "id": "SuO8voI503bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# بارگذاری مدل تولید متن (مثل GPT-2)\n",
        "text_generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "# تولید توضیحات\n",
        "generated_text = text_generator(text, max_new_tokens=150)  # تنظیم تعداد توکن‌های جدید\n",
        "print(generated_text[0]['generated_text'])\n"
      ],
      "metadata": {
        "id": "WdL9UHmR07sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GKAN"
      ],
      "metadata": {
        "id": "QWpzYGV81KGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "\n",
        "class GKANConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GKANConv, self).__init__(aggr='add')  # یا 'mean', 'max'\n",
        "        self.lin = nn.Linear(in_channels, out_channels)\n",
        "        self.att = nn.Parameter(torch.Tensor(1, out_channels))\n",
        "        nn.init.xavier_uniform_(self.att.data)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "        x = self.lin(x)\n",
        "        return self.propagate(edge_index, x=x)\n",
        "\n",
        "    def message(self, x_j, edge_index):\n",
        "        row, col = edge_index\n",
        "        alpha = torch.matmul(x_j, self.att.squeeze())\n",
        "        alpha = F.leaky_relu(alpha)\n",
        "        alpha = F.softmax(alpha, dim=0)\n",
        "        return alpha.unsqueeze(-1) * x_j\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        return aggr_out\n",
        "\n",
        "class GKAN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GKAN, self).__init__()\n",
        "        self.conv1 = GKANConv(1, 16)\n",
        "        self.conv2 = GKANConv(16, 32)\n",
        "        self.conv3 = GKANConv(32, 2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "56g-fkjH1Ite"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "# تنظیم وزن کلاس‌ها برای تعادل\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.0]))\n",
        "\n",
        "# تعریف مدل، optimizer\n",
        "model = GKAN()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# فرض کنید `data` متغیر داده‌ها است\n",
        "model.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # نرمال‌سازی گرادیان‌ها\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "id": "n2eRmN3f2Q38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "_, pred = model(data).max(dim=1)\n",
        "correct = (pred == data.y).sum().item()\n",
        "accuracy = correct / len(data.y)\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "3EY4SrfW23ED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(data)\n",
        "    _, preds = outputs.max(dim=1)\n",
        "\n",
        "\n",
        "y_true = data.y.numpy()\n",
        "y_pred = preds.numpy()\n",
        "\n",
        "# محاسبه F1-Score\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')  # 'weighted' برای محاسبه میانگین وزنی\n",
        "print(f'F1 Score: {f1:.4f}')\n"
      ],
      "metadata": {
        "id": "WLEM1aA344jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "id": "VXMuiThr25dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "id": "Ar1t5k3m27_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# بارگذاری مدل و توکنایزر\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "llm_model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# ساخت متن برای پردازش\n",
        "text = f\"Model GNN Predictions: {pred.tolist()}\\nTrue Labels: {data.y.tolist()}\\nAccuracy: {accuracy:.4f}\\n\"\n",
        "\n",
        "# توکنایز و آماده‌سازی داده‌ها برای مدل LLM\n",
        "inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
        "\n",
        "# پردازش داده‌ها با مدل LLM\n",
        "with torch.no_grad():\n",
        "    outputs = llm_model(**inputs)\n",
        "\n",
        "# خروجی مدل LLM\n",
        "logits = outputs.logits\n",
        "\n",
        "# تبدیل logits به احتمالات (اختیاری)\n",
        "probabilities = torch.softmax(logits, dim=-1)\n"
      ],
      "metadata": {
        "id": "dvA981zt2_v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# بارگذاری مدل تولید متن (مثل GPT-2)\n",
        "text_generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "# تولید توضیحات\n",
        "generated_text = text_generator(f\"Explain the results of GNN model. {text}\", max_length=400)\n",
        "print(generated_text[0]['generated_text'])\n"
      ],
      "metadata": {
        "id": "I2JOLTQ33Dhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# بارگذاری مدل و توکنایزر\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "llm_model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# محاسبه تعداد جاهای خالی و تعداد ماشین‌های پارک شده\n",
        "num_occupied = (data.y == 1).sum().item()\n",
        "num_empty = (data.y == 0).sum().item()\n",
        "\n",
        "# ساخت متن برای پردازش\n",
        "text = (f\"Model GNN Predictions: {pred.tolist()}\\n\"\n",
        "        f\"True Labels: {data.y.tolist()}\\n\"\n",
        "        f\"Accuracy: {accuracy:.4f}\\n\"\n",
        "        f\"Number of parked cars: {num_occupied}\\n\"\n",
        "        f\"Number of empty spaces: {num_empty}\\n\")\n",
        "\n",
        "# توکنایز و آماده‌سازی داده‌ها برای مدل LLM\n",
        "inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
        "\n",
        "# پردازش داده‌ها با مدل LLM\n",
        "with torch.no_grad():\n",
        "    outputs = llm_model(**inputs)\n",
        "\n",
        "# خروجی مدل LLM\n",
        "logits = outputs.logits\n",
        "\n",
        "# تبدیل logits به احتمالات (اختیاری)\n",
        "probabilities = torch.softmax(logits, dim=-1)\n",
        "\n",
        "# چاپ نتایج\n",
        "print(\"Logits:\", logits)\n",
        "print(\"Probabilities:\", probabilities)\n",
        "\n"
      ],
      "metadata": {
        "id": "vjR7EMD93KGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# بارگذاری مدل تولید متن (مثل GPT-2)\n",
        "text_generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "# تولید توضیحات\n",
        "generated_text = text_generator(text, max_new_tokens=150)  # تنظیم تعداد توکن‌های جدید\n",
        "print(generated_text[0]['generated_text'])\n"
      ],
      "metadata": {
        "id": "pm5ewhAo3Ng3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#اتصال نودهای مجاور در ROI"
      ],
      "metadata": {
        "id": "LauQaTbwnOsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node_ids = list(range(len(rois)))\n",
        "graph = nx.Graph()\n",
        "\n",
        "# افزودن نودها به گراف با برچسب‌های پر یا خالی\n",
        "for i, roi in enumerate(rois):\n",
        "    label = labels[i].item()\n",
        "    graph.add_node(node_ids[i], occupied=label)\n",
        "\n",
        "# محاسبه مجاورت و اتصال نودهای مجاور\n",
        "threshold_distance = 50  # فاصله آستانه برای اتصال نودها (باید تنظیم شود)\n",
        "for i in range(len(rois)):\n",
        "    for j in range(i+1, len(rois)):\n",
        "        # محاسبه فاصله بین مراکز ROIها\n",
        "        center_i = np.array([(rois[i][0] + rois[i][2]) / 2, (rois[i][1] + rois[i][3]) / 2])\n",
        "        center_j = np.array([(rois[j][0] + rois[j][2]) / 2, (rois[j][1] + rois[j][3]) / 2])\n",
        "        dist = np.linalg.norm(center_i - center_j)\n",
        "\n",
        "        # اگر فاصله کمتر از آستانه بود، نودها را متصل کن\n",
        "        if dist < threshold_distance:\n",
        "            graph.add_edge(node_ids[i], node_ids[j])\n",
        "\n",
        "# نمایش گراف\n",
        "nx.draw(graph, with_labels=True, node_color=[\"red\" if graph.nodes[i][\"occupied\"] else \"green\" for i in graph.nodes])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tsUBEmFenSUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import from_networkx\n",
        "\n",
        "# تبدیل گراف NetworkX به فرمت داده‌ای PyTorch Geometric\n",
        "data = from_networkx(graph)\n",
        "\n",
        "# افزودن ویژگی‌های نودها به عنوان یک tensor\n",
        "data.x = torch.tensor([graph.nodes[i][\"occupied\"] for i in graph.nodes], dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "# برچسب‌های نودها (occupied یا vacant) را به data.y اختصاص دهید\n",
        "# فرض می‌کنیم 1 برای occupied (پر) و 0 برای vacant (خالی)\n",
        "data.y = torch.tensor([graph.nodes[i][\"occupied\"] for i in graph.nodes], dtype=torch.long)\n",
        "\n",
        "# بررسی داده‌ها\n",
        "print(data)\n"
      ],
      "metadata": {
        "id": "JQo6WVh2noo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.optim as optim\n",
        "\n",
        "# افزودن وزنه‌های کلاس‌ها برای مقابله با عدم تعادل داده‌ها\n",
        "weights = torch.tensor([0.7, 1.3])  # فرضیه: کلاس 0 (خالی) کمتر است\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "# افزایش تعداد لایه‌های GNN یا تغییر نوع مدل\n",
        "class ImprovedGNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedGNN, self).__init__()\n",
        "        self.conv1 = GCNConv(1, 32)\n",
        "        self.conv2 = GCNConv(32, 64)\n",
        "        self.conv3 = GCNConv(64, 32)\n",
        "        self.conv4 = GCNConv(32, 2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv4(x, edge_index)\n",
        "        return torch.log_softmax(x, dim=1)\n",
        "\n",
        "# ادامه مراحل آموزش و ارزیابی با مدل بهبود یافته\n",
        "model = ImprovedGNN()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# آموزش مدل با معماری جدید و وزن‌های کلاس\n",
        "model.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "id": "2_dqmrsFnrVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "_, pred = model(data).max(dim=1)\n",
        "correct = (pred == data.y).sum().item()\n",
        "accuracy = correct / len(data.y)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "RNzxpsQNnugo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "id": "y2mA1w4Tnvwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GAT"
      ],
      "metadata": {
        "id": "BpPBVfYFn1Fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import from_networkx\n",
        "from torch_geometric.nn import GATConv\n",
        "\n",
        "# تبدیل گراف NetworkX به فرمت داده‌ای PyTorch Geometric\n",
        "data = from_networkx(graph)\n",
        "\n",
        "# افزودن ویژگی‌های نودها به عنوان یک tensor\n",
        "data.x = torch.tensor([graph.nodes[i][\"occupied\"] for i in graph.nodes], dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "# برچسب‌های نودها (occupied یا vacant) را به data.y اختصاص دهید\n",
        "data.y = torch.tensor([graph.nodes[i][\"occupied\"] for i in graph.nodes], dtype=torch.long)\n",
        "\n",
        "# تعریف مدل GAT\n",
        "class GAT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GAT, self).__init__()\n",
        "        self.conv1 = GATConv(1, 16, heads=4, dropout=0.6)\n",
        "        self.conv2 = GATConv(16 * 4, 32, heads=4, dropout=0.6)\n",
        "        self.conv3 = GATConv(32 * 4, 2, heads=1, concat=False, dropout=0.6)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        return torch.log_softmax(x, dim=1)\n",
        "\n",
        "# ایجاد مدل، تعریف loss و optimizer\n",
        "model = GAT()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "weights = torch.tensor([0.7, 1.3])  # وزنه‌های کلاس‌ها برای مقابله با عدم تعادل\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "# آموزش مدل\n",
        "model.train()\n",
        "for epoch in range(100):  # تعداد epochها\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
        "\n",
        "# ارزیابی مدل\n",
        "model.eval()\n",
        "_, pred = model(data).max(dim=1)\n",
        "correct = (pred == data.y).sum().item()\n",
        "accuracy = correct / len(data.y)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "x-Lcth8FoKtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "id": "WJJA6Q3Cp3my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# پیش‌بینی با مدل GNN\n",
        "preds = test(model, data)\n",
        "\n",
        "# تبدیل پیش‌بینی‌ها به فرمت متنی\n",
        "pred_texts = [\"Occupied\" if pred == 1 else \"Free\" for pred in preds]"
      ],
      "metadata": {
        "id": "k2uNxtGX4FQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kPGe_xbx5qAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# تنظیم کلید API برای OpenAI\n",
        "openai.api_key = '6fd82421b2cf46959a90c98be2b7bfec'\n",
        "\n",
        "def enhance_predictions_with_llm(pred_texts):\n",
        "    responses = []\n",
        "    for text in pred_texts:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",  # یا مدل LLM دیگر\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"Parking labels are {labels} and GNN predictions are {pred_texts}, how many occupied spaces and empty parking spaces do you think?.\"}\n",
        "            ],\n",
        "            max_tokens=50\n",
        "        )\n",
        "        responses.append(response.choices[0].message['content'].strip())\n",
        "    return responses\n",
        "\n",
        "# بهبود پیش‌بینی‌ها با مدل زبان بزرگ\n",
        "enhanced_predictions = enhance_predictions_with_llm(pred_texts)\n"
      ],
      "metadata": {
        "id": "szXP8zEt4J7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# چاپ نتایج بهبود یافته\n",
        "for original, enhanced in zip(pred_texts, enhanced_predictions):\n",
        "    print(f\"Original Prediction: {original}\")\n",
        "    print(f\"Enhanced by LLM: {enhanced}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "ja-_wjQR4Rjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN And GNN And LLava"
      ],
      "metadata": {
        "id": "N4830g45e2F8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# بارگذاری مدل ResNet از پیش آموزش دیده\n",
        "model_cnn = models.resnet50(pretrained=True)\n",
        "model_cnn.eval()\n",
        "\n",
        "# حذف لایه‌های آخر برای گرفتن ویژگی‌ها\n",
        "model_cnn = torch.nn.Sequential(*list(model_cnn.children())[:-1])\n",
        "\n",
        "# تابع تبدیل ورودی به فرمت قابل استفاده برای مدل ResNet\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # تغییر سایز تصویر\n",
        "    transforms.ToTensor(),          # تبدیل تصویر به tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # نرمال‌سازی\n",
        "])\n",
        "\n",
        "def extract_features_from_roi(image_tensor, roi):\n",
        "    \"\"\"\n",
        "    Extracts visual features from a region of interest (ROI) using a pre-trained CNN.\n",
        "\n",
        "    Args:\n",
        "    - image_tensor (Tensor): The original image as a Tensor.\n",
        "    - roi (list or tuple): Region of interest specified as [xmin, ymin, xmax, ymax].\n",
        "\n",
        "    Returns:\n",
        "    - feature_vector (Tensor): The extracted features as a tensor.\n",
        "    \"\"\"\n",
        "    # تبدیل Tensor به PIL Image برای برش\n",
        "    image_pil = transforms.ToPILImage()(image_tensor)\n",
        "\n",
        "    # اطمینان از اینکه ROI در محدوده تصویر است\n",
        "    width, height = image_pil.size\n",
        "    xmin, ymin, xmax, ymax = roi\n",
        "    xmin = max(0, xmin)\n",
        "    ymin = max(0, ymin)\n",
        "    xmax = min(width, xmax)\n",
        "    ymax = min(height, ymax)\n",
        "\n",
        "    # استخراج ناحیه مورد نظر از تصویر\n",
        "    roi_image = image_pil.crop((xmin, ymin, xmax, ymax))\n",
        "\n",
        "    # اعمال تبدیل‌ها\n",
        "    roi_tensor = transform(roi_image).unsqueeze(0)  # اضافه کردن بُعد batch\n",
        "\n",
        "    # استخراج ویژگی‌ها از مدل CNN\n",
        "    with torch.no_grad():\n",
        "        feature_vector = model_cnn(roi_tensor)\n",
        "\n",
        "    return feature_vector.squeeze()  # حذف بُعد اضافی\n"
      ],
      "metadata": {
        "id": "j4q88dgye62V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def create_edges_from_rois(rois, threshold=100):\n",
        "    \"\"\"\n",
        "    Creates edges for a graph based on the ROIs.\n",
        "\n",
        "    Args:\n",
        "    - rois (list of lists or tuples): List of ROIs, each specified as [xmin, ymin, xmax, ymax].\n",
        "    - threshold (float): Maximum distance between ROIs to create an edge.\n",
        "\n",
        "    Returns:\n",
        "    - edge_index (Tensor): Tensor of shape [2, num_edges] containing pairs of node indices.\n",
        "    \"\"\"\n",
        "    num_rois = len(rois)\n",
        "    edge_index = []\n",
        "\n",
        "    # محاسبه مرکز هر ناحیه (ROI)\n",
        "    centers = [( (roi[0] + roi[2]) / 2, (roi[1] + roi[3]) / 2 ) for roi in rois]\n",
        "\n",
        "    # ایجاد یال‌ها بر اساس فاصله مراکز نواحی\n",
        "    for i in range(num_rois):\n",
        "        for j in range(i + 1, num_rois):\n",
        "            distance = np.linalg.norm(np.array(centers[i]) - np.array(centers[j]))\n",
        "            if distance < threshold:\n",
        "                edge_index.append([i, j])\n",
        "                edge_index.append([j, i])  # اضافه کردن یال در هر دو جهت\n",
        "\n",
        "    # تبدیل به tensor\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "    return edge_index\n"
      ],
      "metadata": {
        "id": "41N26dHAe89b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# فرض کنید که rois و image_raw در دسترس هستند\n",
        "# rois شامل نواحی، و image_raw تصویر اصلی است\n",
        "\n",
        "# 1. استخراج ویژگی‌های هر ناحیه (ROI)\n",
        "features = []\n",
        "for roi in rois:\n",
        "    # استخراج ویژگی‌های بصری از ناحیه با استفاده از یک شبکه CNN\n",
        "    # اینجا می‌توانید یک مدل CNN از پیش آموزش‌دیده مانند ResNet استفاده کنید\n",
        "    feature_vector = extract_features_from_roi(image_raw, roi)\n",
        "    features.append(feature_vector)\n",
        "\n",
        "# تبدیل ویژگی‌ها به یک tensor\n",
        "features = torch.tensor(features)\n",
        "\n",
        "# 2. ایجاد گراف\n",
        "# ایجاد نودها و یال‌های گراف\n",
        "# فرض کنید هر نود با نودهای نزدیک خود ارتباط دارد\n",
        "edge_index = create_edges_from_rois(rois)\n",
        "\n",
        "# ایجاد گراف داده‌ها\n",
        "data = Data(x=features, edge_index=edge_index)\n",
        "\n",
        "# 3. ورودی دادن گراف به GNN\n",
        "# فرض کنید gnn_model مدل GNN شماست\n",
        "gnn_model = MyGNNModel()  # این باید از یک کلاس از پیش تعریف شده باشد\n",
        "\n",
        "# پردازش گراف توسط GNN\n",
        "out = gnn_model(data)\n",
        "\n",
        "# 4. تفسیر خروجی\n",
        "# فرض کنید که خروجی یک پیش‌بینی binary برای هر نود است\n",
        "predictions = (out > 0.5).float()\n",
        "\n",
        "# نمایش نتایج\n",
        "for i, pred in enumerate(predictions):\n",
        "    if pred == 1:\n",
        "        print(f\"ROI {i} (region: {rois[i]}) is occupied.\")\n",
        "    else:\n",
        "        print(f\"ROI {i} (region: {rois[i]}) is empty.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GGv0fz2Sebny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CLIP"
      ],
      "metadata": {
        "id": "Xb_ilxcPeeYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "\n",
        "# بارگذاری مدل CLIP و پردازشگر آن\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "# تبدیل تصویر پیش‌پردازش شده به PIL image برای ورودی CLIP\n",
        "image_pil = Image.fromarray((image.permute(1, 2, 0).numpy() * 255).astype(np.uint8))\n",
        "\n",
        "# پردازش تصویر با استفاده از CLIPProcessor\n",
        "inputs = processor(images=image_pil, return_tensors=\"pt\")\n",
        "\n",
        "# استخراج ویژگی‌ها از مدل CLIP\n",
        "with torch.no_grad():\n",
        "    features = model.get_image_features(**inputs)\n",
        "\n",
        "n = len(rois_batch[0])  # تعداد ROIها در هر تصویر\n",
        "features = torch.randn((n, 512))  # فرضی که هر ROI دارای ویژگی‌های [512] است\n",
        "\n",
        "# نمایش ویژگی‌های استخراج‌شده\n",
        "print(features.shape)  # بررسی ابعاد ویژگی‌ها\n"
      ],
      "metadata": {
        "id": "zrOXGcjx3BI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6oCVzS1GF1EA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# فرض کنید که features شامل ویژگی‌های استخراج‌شده از هر فضای پارکینگ است\n",
        "x = features  # ویژگی‌های نودها\n",
        "\n",
        "edges = list(combinations(range(n), 2))\n",
        "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "\n",
        "# برای گراف غیرجهت‌دار، یال‌ها را دوباره به ترتیب معکوس اضافه می‌کنیم\n",
        "edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
        "\n",
        "# ساختار داده‌ی گراف\n",
        "data = Data(x=x, edge_index=edge_index, y=labels)"
      ],
      "metadata": {
        "id": "ghijUqfK3M9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# پارامترهای مدل\n",
        "in_channels = features.shape[1]  # تعداد ویژگی‌های ورودی (ابعاد ویژگی‌های تصویری)\n",
        "hidden_channels = 16  # تعداد نودهای مخفی\n",
        "out_channels = 2  # خروجی‌های نهایی (دو کلاس: اشغال یا خالی بودن)\n",
        "\n",
        "# ایجاد مدل GCN\n",
        "model = GCN(in_channels, hidden_channels, out_channels)"
      ],
      "metadata": {
        "id": "AZIBptEDGzVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# تعریف optimizer و loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "hFWw83OhG6DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(200):  # 200 دوره برای آموزش\n",
        "    optimizer.zero_grad()  # صفر کردن گرادیان‌ها\n",
        "    out = model(data)  # عبور داده از مدل GCN\n",
        "    loss = criterion(out, labels)  # محاسبه loss\n",
        "    loss.backward()  # محاسبه گرادیان‌ها\n",
        "    optimizer.step()  # به‌روزرسانی وزن‌ها\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "id": "ElNbuCf5G8Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model(data)\n",
        "    pred = out.argmax(dim=1)  # پیش‌بینی کلاس‌ها\n",
        "    correct = (pred == labels).sum().item()  # تعداد پیش‌بینی‌های صحیح\n",
        "    accuracy = correct / len(labels)  # محاسبه دقت\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "hFnlXXvDHM1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "z3EA-_sRHaep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# بارگذاری مدل BERT و tokenizer آن\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# نمونه متن\n",
        "texts = [\n",
        "    \"The parking space is occupied by a Blue car.\",\n",
        "    \"The parking space is empty.\",\n",
        "    \"The parking space is occupied by a Red car.\",\n",
        "    \"The parking space is occupied by a Yellow car.\",\n",
        "    \"The parking space is occupied by a Green car.\",\n",
        "    \"The parking space is occupied by a Black car.\",\n",
        "    \"The parking space is occupied by a White car.\",\n",
        "    \"The parking space is occupied by a blue car.\",\n",
        "    \"The parking space is occupied by a Orange car.\",\n",
        "    \"The parking space is occupied by a Gold car.\",\n",
        "    \"The parking space is occupied by a Pink car.\",\n",
        "    \"The parking space is occupied by a Purple car.\",\n",
        "    \"The parking space is occupied by a magenta car.\",\n",
        "    \"The parking space is occupied by a cyan car.\",\n",
        "    \"The parking space is occupied by a Brown car.\",\n",
        "    \"The parking space is occupied by a Gray car.\",\n",
        "    \"The parking space is occupied by a Turquoise car.\",\n",
        "    \"The parking space is occupied by a Light Blue car.\",\n",
        "    \"The parking space is occupied by a Light Green car.\",\n",
        "    \"The parking space is occupied by a Pale Yellow car.\",\n",
        "    \"The parking space is occupied by a Dark Orange car.\",\n",
        "    \"The parking space is occupied by a Dark Blue car.\",\n",
        "    \"The parking space is occupied by a Dark Green car.\",\n",
        "    \"The parking space is occupied by a Dark Red car.\",\n",
        "    \"The parking space is occupied by a Dark Purple car.\",\n",
        "    \"The parking space is occupied by a Light Pink car.\",\n",
        "    \"The parking space is occupied by a Light Brown car.\",\n",
        "    \"The parking space is occupied by a Silver car.\",\n",
        "    \"The parking space is occupied by a Bronze car.\",\n",
        "    \"The parking space is occupied by a Teal car.\",\n",
        "    \"The parking space is occupied by a Azure car.\",\n",
        "    \"The parking space is occupied by a Sky Blue car.\",\n",
        "    \"The parking space is occupied by a Magenta car.\",\n",
        "    \"The parking space is occupied by a Olive Green car.\",\n",
        "    \"The parking space is occupied by a Beige car.\",\n",
        "    \"The parking space is occupied by a Fuchsia car.\",\n",
        "    \"The parking space is occupied by a Emerald Green car.\",\n",
        "    \"The parking space is occupied by a Indigo car.\",\n",
        "    \"The parking space is occupied by a Khaki car.\",\n",
        "    \"The parking space is occupied by a Maroon car.\",\n",
        "    \"The parking space is occupied by a Brick Red car.\",\n",
        "    \"The parking space is occupied by a Ruby Red car.\",\n",
        "    \"The parking space is occupied by a Olive car.\",\n",
        "    \"The parking space is occupied by a Navy car.\",\n",
        "    \"The parking space is occupied by a Crimson car.\",\n",
        "    \"The parking space is occupied by a Wheat car.\",\n",
        "    \"The parking space is occupied by a Cobalt Blue car.\",\n",
        "    \"The parking space is occupied by a Champagne car.\",\n",
        "    \"The parking space is occupied by a Lemon car.\",\n",
        "    \"The parking space is occupied by a Eggplant car.\",\n",
        "    \"The parking space is occupied by a Ice Blue car.\",\n",
        "    \"The parking space is occupied by a Cream car.\",\n",
        "    \"The parking space is occupied by a Coral car.\",\n",
        "    \"The parking space is occupied by a Navy Blue car.\",\n",
        "    \"The parking space is occupied by a Golden Yellow car.\",\n",
        "    \"The parking space is occupied by a Mint Green car.\",\n",
        "    \"The parking space is occupied by a Dark Brown car.\",\n",
        "    \"The parking space is occupied by a Deep Magenta car.\",\n",
        "    \"The parking space is occupied by a Silver Gray car.\",\n",
        "    \"The parking space is occupied by a Brick Orange car.\",\n",
        "    \"The parking space is occupied by a Banana Yellow car.\",\n",
        "    \"The parking space is occupied by a Wine Red car.\",\n",
        "    \"The parking space is occupied by a Pumpkin Orange car.\",\n",
        "    \"The parking space is occupied by a Ocean Blue car.\",\n",
        "    \"The parking space is occupied by a Rose Pink car.\",\n",
        "    \"The parking space is occupied by a Copper car.\",\n",
        "    \"The parking space is occupied by a Light Purple car.\",\n",
        "    \"The parking space is occupied by a Herbal Green car.\",\n",
        "    \"The parking space is occupied by a Peach car.\"\n",
        "]\n",
        "\n",
        "# تبدیل متن‌ها به token و استخراج ویژگی‌ها\n",
        "inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    text_features = outputs.last_hidden_state.mean(dim=1)  # میانگین‌گیری روی طول توکن‌ها\n",
        "\n",
        "print(text_features.shape)  # ابعاد ویژگی‌های متنی\n"
      ],
      "metadata": {
        "id": "kZGkgvRzHgxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# فرض کنید ویژگی‌های تصویری را از قبل داریم\n",
        "combined_features = torch.cat([features, text_features], dim=1)\n",
        "\n",
        "# جایگزینی ویژگی‌های نودها با ویژگی‌های ترکیبی\n",
        "data.x = combined_features\n"
      ],
      "metadata": {
        "id": "cGLQYULHHjyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تنظیم مدل برای آموزش دوباره\n",
        "model = GCN(combined_features.shape[1], hidden_channels, out_channels)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# آموزش مدل GNN با ویژگی‌های ترکیبی\n",
        "model.train()\n",
        "for epoch in range(200):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
        "\n",
        "# ارزیابی مدل\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model(data)\n",
        "    pred = out.argmax(dim=1)\n",
        "    correct = (pred == labels).sum().item()\n",
        "    accuracy = correct / len(labels)\n",
        "\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "d5Lpvwx7HmF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# مدل در حالت ارزیابی قرار داده می‌شود\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model(data)\n",
        "    pred = out.argmax(dim=1)  # پیش‌بینی کلاس‌ها\n",
        "    true_labels = labels\n",
        "\n",
        "# محاسبه معیارهای مختلف\n",
        "accuracy = accuracy_score(true_labels, pred)\n",
        "precision = precision_score(true_labels, pred, average='macro')\n",
        "recall = recall_score(true_labels, pred, average='macro')\n",
        "f1 = f1_score(true_labels, pred, average='macro')\n",
        "cm = confusion_matrix(true_labels, pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'F1 Score: {f1:.2f}')\n",
        "print(f'Confusion Matrix:\\n{cm}')\n"
      ],
      "metadata": {
        "id": "BB5GzpvwIJiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# به عنوان مثال، کاهش نرخ یادگیری\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "gwTIN8c5IKU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# اضافه کردن Dropout به مدل GNN\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "        self.dropout = torch.nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# بازآموزی مدل با Dropout\n",
        "model = GCN(combined_features.shape[1], hidden_channels, out_channels)\n"
      ],
      "metadata": {
        "id": "HWOTyw6KINfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "# ایجاد چندین batch برای cross-validation\n",
        "data_loader = DataLoader([data], batch_size=1, shuffle=True)\n",
        "\n",
        "# اجرای cross-validation\n",
        "for fold, batch in enumerate(data_loader):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(batch)\n",
        "    loss = criterion(out, batch.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f'Fold {fold}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "id": "4XqfkWKVIPlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ذخیره مدل نهایی\n",
        "torch.save(model.state_dict(), 'final_gnn_model.pth')\n",
        "\n",
        "# بارگذاری مدل برای استفاده در آینده\n",
        "model.load_state_dict(torch.load('final_gnn_model.pth'))\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "LpoNR51CIPgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # مدل را در حالت ارزیابی قرار می‌دهیم\n",
        "with torch.no_grad():\n",
        "    # داده‌ها باید به شکل مناسب برای مدل ارسال شوند\n",
        "    out = model(data)\n",
        "    predictions = out.argmax(dim=1)  # پیش‌بینی برچسب‌ها برای هر نود"
      ],
      "metadata": {
        "id": "OVq3wZmRVTIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model(data)\n",
        "    pred = out.argmax(dim=1)  # پیش‌بینی کلاس‌ها\n",
        "    empty_spaces = (pred == labels).sum().item()  # تعداد پیش‌بینی‌های صحیح\n",
        "    total_spaces = len(labels)\n",
        "    filled_spaces = total_spaces - empty_spaces\n",
        "\n",
        "print(f'Number of empty spaces: {empty_spaces}')\n",
        "print(f'Number of filled spaces: {filled_spaces}')"
      ],
      "metadata": {
        "id": "YBrad6_eVVh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#llava-1.5-7b-hf"
      ],
      "metadata": {
        "id": "IdUNN084Ws1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U transformers==4.37.2\n",
        "!pip install -q bitsandbytes==0.41.3 accelerate==0.25.0"
      ],
      "metadata": {
        "id": "ujL7ErByWwF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")"
      ],
      "metadata": {
        "id": "XSgDirQaW2nA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
        "\n",
        "pipe = pipeline(\"image-to-text\", model=model_id, model_kwargs={\"quantization_config\": quantization_config})"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mrCQgTYyW6XD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_new_tokens = 200\n",
        "prompt = \"USER: <image>\\nHow many empty and full spaces are there in this parking lot?\\nASSISTANT:\"\n",
        "\n",
        "outputs = pipe(image, prompt=prompt, generate_kwargs={\"max_new_tokens\": 200})"
      ],
      "metadata": {
        "id": "H_XLHJB0W6zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "PMoeLkaUW-qW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LLAVA"
      ],
      "metadata": {
        "id": "XwCz3rCy4zQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/haotian-liu/LLaVA.git\n",
        "!cd LLaVA"
      ],
      "metadata": {
        "id": "bAY208vG41S5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create -n llava python=3.10 -y\n",
        "!conda activate llava\n",
        "!python -m pip install --upgrade pip  # enable PEP 660 support\n",
        "!pip install torch==2.0.1+cu117 torchvision==0.15.2+cu117 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu117\n",
        "!pip install -e .\n",
        "!pip uninstall bitsandbytes\n"
      ],
      "metadata": {
        "id": "ObXRaRyq5Dt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import CLIPModel, CLIPProcessor\n",
        "\n",
        "# دانلود مدل و پردازشگر CLIP از Hugging Face\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n"
      ],
      "metadata": {
        "id": "zmZEGAsh8qfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# بارگذاری تصویر\n",
        "image = Image.open(\"/content/parking-space-occupancy/dataset/data/images/GOPR0024.JPG\")\n",
        "\n",
        "# پردازش تصویر با استفاده از CLIPProcessor\n",
        "inputs = processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "# عبور دادن تصویر از طریق مدل\n",
        "with torch.no_grad():\n",
        "    outputs = model.get_image_features(**inputs)\n",
        "\n",
        "# نمایش ویژگی‌های تصویر\n",
        "print(outputs)\n"
      ],
      "metadata": {
        "id": "PlwHSnu38yYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN+llava-1.5-7b-hf"
      ],
      "metadata": {
        "id": "4vV8kPRXEYcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision transformers"
      ],
      "metadata": {
        "collapsed": true,
        "id": "cmpNhWUZEbk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install git+https://github.com/liuhaotian/LLaVA.git\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fAwNqMT1J0I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# استفاده از مدل BLIP\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "AXpB0No4Jise"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# تعریف CNN بهبود یافته\n",
        "class ImprovedCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 32 * 32, 512)\n",
        "        self.fc2 = nn.Linear(512, 2)  # دو کلاس: پارک شده / خالی\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 32 * 32)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# لود داده‌های آموزشی\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root='/content/parking-space-occupancy/dataset', transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# تعریف مدل، تابع هزینه و بهینه‌ساز\n",
        "cnn_model = ImprovedCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
        "\n",
        "# آموزش مدل CNN\n",
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    for epoch in range(10):  # تعداد epoch ها را می‌توانید تغییر دهید\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')\n",
        "\n",
        "train(cnn_model, train_loader, criterion, optimizer, device)\n"
      ],
      "metadata": {
        "id": "4PsWrS2sEiKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# تابع پیش‌بینی نهایی\n",
        "def predict_parking_occupancy(image_path):\n",
        "    # پیش‌پردازش تصویر\n",
        "    image = Image.open(image_path)\n",
        "    input_image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # پیش‌بینی با مدل CNN\n",
        "    cnn_model.eval()\n",
        "    with torch.no_grad():\n",
        "        cnn_output = cnn_model(input_image)\n",
        "        _, predicted = torch.max(cnn_output, 1)\n",
        "\n",
        "    # استفاده از مدل Llava-1.5-7B-HF برای تحلیل تصویر\n",
        "    inputs = processor(image, return_tensors=\"pt\").to(device)\n",
        "    outputs = model.generate(**inputs)\n",
        "    text_output = processor.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # ترکیب نتایج CNN و Llava\n",
        "    if predicted.item() == 1:  # فرض بر این که 1 به معنای پارک شده است\n",
        "        return f\"Parking Occupied. Llava says: {text_output}\"\n",
        "    else:\n",
        "        return f\"Parking Free. Llava says: {text_output}\"\n",
        "\n",
        "# نمونه استفاده\n",
        "print(predict_parking_occupancy('/content/parking-space-occupancy/dataset/data/images/GOPR6590.JPG'))\n"
      ],
      "metadata": {
        "id": "ewhbfQEAEmoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#faster_RCNN"
      ],
      "metadata": {
        "id": "dyD6xQSto_NJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from google.colab.patches import cv2_imshow  # برای نمایش تصاویر در Colab\n",
        "\n",
        "# بارگیری مدل Faster R-CNN از پیش‌آموزش‌دیده شده\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# بارگیری تصویر و تبدیل آن به فرمت قابل استفاده برای مدل\n",
        "def transform_image(image):\n",
        "    transform = T.Compose([T.ToTensor()])\n",
        "    return transform(image).unsqueeze(0)  # اضافه کردن ابعاد batch\n",
        "\n",
        "# تشخیص اشیاء در تصویر\n",
        "def detect_objects(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    tensor_image = transform_image(image_rgb)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictions = model(tensor_image)\n",
        "\n",
        "    return image, predictions\n",
        "\n",
        "# رسم جعبه‌های محدودکننده\n",
        "def draw_boxes(image, predictions):\n",
        "    boxes = predictions[0]['boxes'].cpu().numpy()\n",
        "    scores = predictions[0]['scores'].cpu().numpy()\n",
        "    threshold = 0.5  # آستانه برای نمایش جعبه‌های محدودکننده\n",
        "\n",
        "    for i in range(len(scores)):\n",
        "        if scores[i] > threshold:\n",
        "            box = boxes[i].astype(int)\n",
        "            x1, y1, x2, y2 = box\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "    return image\n",
        "\n",
        "# مسیر تصویر ورودی\n",
        "image_path = '/content/drive/MyDrive/Colab Notebooks/parking-space-occupancy-main/dataset/data/images/GOPR6590.JPG'\n",
        "\n",
        "# تشخیص اشیاء و رسم جعبه‌های محدودکننده\n",
        "image, predictions = detect_objects(image_path)\n",
        "image_with_boxes = draw_boxes(image, predictions)\n",
        "\n",
        "# نمایش تصویر در Google Colab\n",
        "cv2_imshow(image_with_boxes)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "V5-c5fEuAB1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ُStep 1"
      ],
      "metadata": {
        "id": "oNJ54-eEWvx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from google.colab.patches import cv2_imshow  # برای نمایش تصاویر در Google Colab\n",
        "\n",
        "# بارگیری مدل Faster R-CNN از پیش‌آموزش‌دیده شده\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# بارگیری تصویر و تبدیل آن به فرمت قابل استفاده برای مدل\n",
        "def transform_image(image):\n",
        "    transform = T.Compose([T.ToTensor()])\n",
        "    return transform(image).unsqueeze(0)  # اضافه کردن ابعاد batch\n",
        "\n",
        "# تشخیص اشیاء در تصویر\n",
        "def detect_objects(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    tensor_image = transform_image(image_rgb)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictions = model(tensor_image)\n",
        "\n",
        "    return image, predictions\n",
        "\n",
        "# رسم جعبه‌های محدودکننده و اختصاص Local ID\n",
        "def draw_boxes_with_ids(image, predictions):\n",
        "    boxes = predictions[0]['boxes'].cpu().numpy()\n",
        "    scores = predictions[0]['scores'].cpu().numpy()\n",
        "    threshold = 0.5  # آستانه برای نمایش جعبه‌های محدودکننده\n",
        "\n",
        "    for i in range(len(scores)):\n",
        "        if scores[i] > threshold:\n",
        "            box = boxes[i].astype(int)\n",
        "            x1, y1, x2, y2 = box\n",
        "\n",
        "            # رسم جعبه محدودکننده\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "            # رسم Local ID\n",
        "            local_id = i + 1  # اختصاص یک ID یکتا به هر ماشین (شروع از 1)\n",
        "            label = f'ID: {local_id}'\n",
        "            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "    return image\n",
        "\n",
        "# مسیر تصویر ورودی\n",
        "image_path = '/content/drive/MyDrive/Colab Notebooks/parking-space-occupancy-main/dataset/data/images/GOPR6590.JPG'\n",
        "\n",
        "# تشخیص اشیاء و رسم جعبه‌های محدودکننده با Local ID\n",
        "image, predictions = detect_objects(image_path)\n",
        "image_with_boxes_and_ids = draw_boxes_with_ids(image, predictions)\n",
        "\n",
        "# نمایش تصویر در Google Colab\n",
        "cv2_imshow(image_with_boxes_and_ids)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "H-RkrD7ZBNyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 2"
      ],
      "metadata": {
        "id": "yx73jVXAWzM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import networkx as nx  # برای ساخت گراف\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# بارگیری مدل Faster R-CNN از پیش‌آموزش‌دیده شده\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# بارگیری تصویر و تبدیل آن به فرمت قابل استفاده برای مدل\n",
        "def transform_image(image):\n",
        "    transform = T.Compose([T.ToTensor()])\n",
        "    return transform(image).unsqueeze(0)  # اضافه کردن ابعاد batch\n",
        "\n",
        "# تشخیص اشیاء در تصویر\n",
        "def detect_objects(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    tensor_image = transform_image(image_rgb)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictions = model(tensor_image)\n",
        "\n",
        "    return image, predictions\n",
        "\n",
        "# رسم جعبه‌های محدودکننده و اختصاص Local ID\n",
        "def draw_boxes_with_ids(image, predictions):\n",
        "    boxes = predictions[0]['boxes'].cpu().numpy()\n",
        "    scores = predictions[0]['scores'].cpu().numpy()\n",
        "    threshold = 0.5  # آستانه برای نمایش جعبه‌های محدودکننده\n",
        "    local_ids = []\n",
        "\n",
        "    for i in range(len(scores)):\n",
        "        if scores[i] > threshold:\n",
        "            box = boxes[i].astype(int)\n",
        "            x1, y1, x2, y2 = box\n",
        "\n",
        "            # رسم جعبه محدودکننده\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "            # رسم Local ID\n",
        "            local_id = i + 1  # اختصاص یک ID یکتا به هر ماشین (شروع از 1)\n",
        "            label = f'ID: {local_id}'\n",
        "            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "            # ذخیره Local ID و مرکز جعبه محدودکننده\n",
        "            center_x = (x1 + x2) // 2\n",
        "            center_y = (y1 + y2) // 2\n",
        "            local_ids.append((local_id, center_x, center_y))\n",
        "\n",
        "    return image, local_ids\n",
        "\n",
        "# ایجاد گراف از Local ID ها\n",
        "def create_graph(local_ids, distance_threshold=100):\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # افزودن نودها\n",
        "    for local_id, x, y in local_ids:\n",
        "        G.add_node(local_id, pos=(x, y))\n",
        "\n",
        "    # افزودن یال‌ها بر اساس فاصله\n",
        "    for i in range(len(local_ids)):\n",
        "        for j in range(i + 1, len(local_ids)):\n",
        "            id1, x1, y1 = local_ids[i]\n",
        "            id2, x2, y2 = local_ids[j]\n",
        "            distance = np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
        "            if distance < distance_threshold:\n",
        "                G.add_edge(id1, id2)\n",
        "\n",
        "    return G\n",
        "\n",
        "# مسیر تصویر ورودی\n",
        "image_path = '/content/drive/MyDrive/Colab Notebooks/parking-space-occupancy-main/dataset/data/images/GOPR6590.JPG'\n",
        "\n",
        "# تشخیص اشیاء و رسم جعبه‌های محدودکننده با Local ID\n",
        "image, predictions = detect_objects(image_path)\n",
        "image_with_boxes_and_ids, local_ids = draw_boxes_with_ids(image, predictions)\n",
        "\n",
        "# ایجاد گراف\n",
        "G = create_graph(local_ids)\n",
        "\n",
        "# نمایش گراف\n",
        "pos = nx.get_node_attributes(G, 'pos')\n",
        "nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=500, edge_color='gray')\n",
        "\n",
        "# نمایش تصویر در Google Colab\n",
        "cv2_imshow(image_with_boxes_and_ids)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "FBrncHycW43C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ُStep 3"
      ],
      "metadata": {
        "id": "-pcmMw0rZ7xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "id": "SQ_lWfQlaAGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "# تبدیل گراف به فرمت قابل استفاده برای GNN\n",
        "def convert_graph_to_gnn_data(G):\n",
        "    nodes = list(G.nodes())\n",
        "    edges = list(G.edges())\n",
        "\n",
        "    # ساخت لیست از ویژگی‌های نودها (در اینجا فقط موقعیت نودها را در نظر می‌گیریم)\n",
        "    x = torch.tensor([G.nodes[node]['pos'] for node in nodes], dtype=torch.float)\n",
        "\n",
        "    # ساخت لیست از یال‌ها\n",
        "    edge_index = torch.tensor([[nodes.index(edge[0]), nodes.index(edge[1])] for edge in edges], dtype=torch.long).t().contiguous()\n",
        "\n",
        "    # برچسب‌ها (در اینجا فرض شده که همه نودها باید به یک کلاس مشخص تعلق داشته باشند؛ نیاز به برچسب‌گذاری دارید)\n",
        "    y = torch.tensor([0] * len(nodes), dtype=torch.long)  # جایگذاری y با برچسب‌های واقعی\n",
        "\n",
        "    data = Data(x=x, edge_index=edge_index, y=y)\n",
        "    return data\n",
        "\n",
        "# تبدیل گراف به داده GNN\n",
        "gnn_data = convert_graph_to_gnn_data(G)\n"
      ],
      "metadata": {
        "id": "zq5HJUEIZ-Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, hidden_channels, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Wt0iAtQbaGRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# پارامترهای مدل\n",
        "num_node_features = gnn_data.num_node_features\n",
        "hidden_channels = 16\n",
        "num_classes = 2  # فرض کنیم دو کلاس داشته باشیم: اشغال شده و خالی\n",
        "\n",
        "# ساخت مدل\n",
        "model = GCN(num_node_features, hidden_channels, num_classes)\n",
        "\n",
        "# تعریف optimizer و loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# آموزش مدل\n",
        "model.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(gnn_data)\n",
        "    loss = criterion(out, gnn_data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "id": "D8q1EfSFaKAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model(gnn_data)\n",
        "    pred = out.argmax(dim=1)\n",
        "    print('Predictions:', pred)\n"
      ],
      "metadata": {
        "id": "Mcj8TMwsaNVh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}